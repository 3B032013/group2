import os
import json
import pandas as pd
import requests
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
from io import BytesIO
import numpy as np
from tqdm import tqdm
import urllib.parse

# 1. æ¨¡å‹åˆå§‹åŒ– (ResNet-50)
model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
model = nn.Sequential(*list(model.children())[:-1])
model.eval()

preprocess = transforms.Compose([
    transforms.Resize(256), transforms.CenterCrop(224),
    transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

def run_all():
    # è·¯å¾‘è¨­å®š
    data_dir = r'c:\Users\Jhen\Desktop\group2\group2-master\data'
    json_path = os.path.join(data_dir, 'AttractionList.json')
    img_dir = os.path.join(data_dir, 'attraction_images')
    output_npy = os.path.join(data_dir, 'attraction_image_index.npy')
    
    if not os.path.exists(img_dir): os.makedirs(img_dir)

    print(f"æ­£åœ¨è®€å– JSON: {json_path}")
    with open(json_path, 'r', encoding='utf-8') as f:
        full_data = json.load(f)
    
    # ğŸ’¡ é—œéµä¿®æ­£ï¼šé€²å…¥ Attractions å±¤ç´š
    attractions_list = full_data.get('Attractions', [])
    print(f"æˆåŠŸè§£æï¼å…±æœ‰ {len(attractions_list)} ç­†æ™¯é»è³‡æ–™ã€‚")

    feature_db = {}
    success_count = 0
    
    # å»ºè­°å…ˆæ¸¬è©¦ 3000 ç­†ï¼Œçœ‹é³¥çš„ç…§ç‰‡æœ‰æ²’æœ‰è®Šæº–
    test_limit = 3000 
    
    print(f"é–‹å§‹ä¸‹è¼‰åœ–ç‰‡ä¸¦å»ºç«‹ ResNet-50 ç‰¹å¾µç´¢å¼• (é è¨ˆè™•ç†å‰ {test_limit} ç­†)...")
    
    for i, item in enumerate(tqdm(attractions_list[:test_limit])):
        attr_id = item.get('AttractionID')
        images = item.get('Images', [])
        
        if not images or not attr_id:
            continue
            
        # å–å¾—ç¬¬ä¸€å¼µåœ–ç‰‡ç¶²å€
        raw_url = images[0].get('URL')
        if not raw_url:
            continue
            
        try:
            # è™•ç†ç¶²å€ä¸­çš„ç‰¹æ®Šå­—å…ƒç·¨ç¢¼
            encoded_url = urllib.parse.quote(raw_url, safe='/:?=&')
            # ğŸ’¡ å¢åŠ  headers ä¸¦é—œé–‰ SSL é©—è­‰ï¼Œé€šå¸¸å¯ä»¥æŠ“åˆ°æ›´å¤šæ”¿åºœç¶²ç«™åœ–ç‰‡
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            resp = requests.get(encoded_url, headers=headers, timeout=10, verify=False)
            
            if resp.status_code == 200:
                img = Image.open(BytesIO(resp.content)).convert('RGB')
                
                # å„²å­˜å¯¦é«”ç…§ç‰‡åˆ°è³‡æ–™å¤¾
                img_filename = f"{attr_id}.jpg"
                img.save(os.path.join(img_dir, img_filename))

                # æå– AI ç‰¹å¾µå‘é‡
                img_t = preprocess(img)
                batch_t = torch.unsqueeze(img_t, 0)
                with torch.no_grad():
                    feat = model(batch_t).flatten().numpy()
                    feat = feat / np.linalg.norm(feat) # å–®ä½åŒ–æé«˜ç²¾æº–åº¦
                
                feature_db[attr_id] = feat
                success_count += 1
        except Exception as e:
            # print(f"è·³é {attr_id}: {e}")
            continue

    # å„²å­˜ç´¢å¼•
    np.save(output_npy, feature_db)
    print(f"\nğŸ‰ å¤§åŠŸå‘Šæˆï¼")
    print(f"æˆåŠŸä¸‹è¼‰åœ–ç‰‡æ•¸é‡: {success_count}")
    print(f"è«‹ç¢ºèªæ­¤è·¯å¾‘å·²æœ‰ç…§ç‰‡: {img_dir}")

if __name__ == "__main__":
    run_all()